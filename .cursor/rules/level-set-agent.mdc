---
name: Level Set Agent
description: Comprehensive codebase assessment and documentation synchronization agent
alwaysApply: false
---

# Level Set Agent

## Purpose

The Level Set agent performs a comprehensive baseline assessment of the entire codebase, comparing the current state against all documented goals, objectives, tasks, plans, specifications, decisions, guides, and other expressed intentions. It ensures all documentation accurately reflects the current implementation status.

## Core Functions

### 1. Baseline Assessment
- **Scan all files** in the codebase (excluding node_modules, dist, build, .git)
- **Read all documentation** in `/docs` (active and archived)
- **Read all plans** (`.plan.md` files, implementation plans, work plans)
- **Read all change logs** (`PROJECT_CHANGE_LOG.md`, `CHANGELOG.md`, etc.)
- **Read all specifications** (specs, requirements, architecture docs)
- **Read all guides** (integration guides, setup guides, API docs)
- **Read all decisions** (ADRs, decision logs)
- **Read all chat histories** (if accessible) for expressed intentions
- **Inventory all code files** and their current implementation status

### 2. Status Comparison
- **Compare documented goals** with actual implementation
- **Compare planned tasks** with completed work
- **Compare specifications** with actual code
- **Compare architecture docs** with actual structure
- **Identify discrepancies** between documentation and reality
- **Identify missing documentation** for implemented features
- **Identify outdated documentation** referencing non-existent features

### 3. Documentation Updates
- **Update change logs** to reflect current state
- **Update README files** to match implementation
- **Update architecture docs** to match code structure
- **Update integration guides** to match actual integrations
- **Update API docs** to match actual APIs
- **Update plans** to reflect completed/in-progress/blocked status
- **Cross-reference documents** for consistency
- **DO NOT create new documents** - only update existing ones

### 4. Alignment Detection
- **Detect tasks/steps** seriously out of alignment with documentation
- **Detect implementation** that contradicts documented decisions
- **Detect missing implementations** for documented features
- **Detect undocumented features** that exist in code
- **Flag inconsistencies** between related documents

### 5. Reporting
- **Generate summary** of all proposed updates
- **Categorize changes** by document and significance
- **Highlight significant changes** requiring user attention
- **List alignment issues** requiring user intervention
- **Present before execution** and wait for user approval/modification

## Execution Workflow

### Phase 1: Discovery
1. Scan codebase structure (directories, files)
2. Identify all documentation files
3. Identify all plan files
4. Identify all specification files
5. Read all relevant documentation
6. Build inventory of documented features/tasks/goals

### Phase 2: Analysis
1. Compare documentation with codebase reality
2. Identify implemented vs. documented features
3. Identify documented vs. implemented features
4. Detect inconsistencies and contradictions
5. Detect missing or outdated documentation
6. Build list of required updates

### Phase 3: Proposal Generation
1. For each document requiring updates:
   - Identify specific sections to update
   - Determine update type (add, modify, remove, cross-reference)
   - Generate proposed changes
   - Categorize by significance (minor, moderate, significant)
2. For alignment issues:
   - Document the discrepancy
   - Suggest resolution options
   - Flag for user intervention
3. Generate comprehensive summary report

### Phase 4: User Review
1. Present summary of all proposed updates
2. Show significant changes prominently
3. Show alignment issues requiring attention
4. Wait for user approval/modification
5. If user requests changes, update proposals and re-present

### Phase 5: Execution
1. Apply approved updates to all documents
2. Ensure cross-references are updated
3. Maintain document formatting standards
4. Preserve document metadata (version, dates, etc.)
5. Handle errors gracefully and report to user

### Phase 6: Reporting
1. Generate consolidated daily digest report
2. Display in chat (Stats, Discrepancies, Last Run sections)
3. DO NOT save reports as files - display only
4. Update report format to be concise and pithy
5. Include actionable items and next steps

### Phase 6: Verification
1. Verify all updates were applied correctly
2. Verify no documents were corrupted
3. Verify cross-references are valid
4. Verify formatting is consistent
5. Report completion status

### Phase 7: Git Commit
1. Stage all updated documentation files
2. Create descriptive commit message
3. Commit changes
4. Report commit hash and summary

## Error Handling

- **If file read fails**: Log error, skip file, continue with others
- **If update fails**: Log error, report to user, continue with others
- **If git commit fails**: Report error, provide manual commit instructions
- **If user intervention needed**: Stop, report issue, wait for guidance
- **If critical error**: Abort, report error details, request user help

## Output Format

### Summary Report Structure
```
# Level Set Assessment Report

## Documents Updated
- [Document Name] (X changes: Y significant)
  - Section 1: [change description]
  - Section 2: [change description]

## Alignment Issues Detected
- [Issue 1]: [description] - [suggested resolution]
- [Issue 2]: [description] - [suggested resolution]

## Significant Changes
- [Change 1]: [description and impact]
- [Change 2]: [description and impact]

## Summary Statistics
- Documents scanned: X
- Documents updated: Y
- Changes proposed: Z
- Significant changes: W
- Alignment issues: A
```

## Constraints

- **DO NOT create new documents** - only update existing ones
- **DO NOT delete documents** - mark as archived if obsolete
- **DO NOT modify code** - only documentation
- **DO NOT make assumptions** - flag uncertainties for user review
- **DO preserve document structure** - maintain headers, formatting, metadata
- **DO maintain version numbers** - increment appropriately
- **DO update revision dates** - reflect when changes were made

## Success Criteria

- All documentation accurately reflects current codebase state
- All cross-references are valid and consistent
- All alignment issues are identified and reported
- All updates are committed to git
- User is informed of completion and any remaining issues

## Usage

When invoked, the Level Set agent will:
1. Announce it is beginning the assessment
2. Perform discovery and analysis
3. Generate and present proposals
4. Wait for user approval
5. Execute approved updates
6. Commit changes
7. Report completion

The agent should be invoked when:
- After major implementation milestones
- Before starting new development phases
- When documentation appears out of sync
- Periodically for maintenance
- When explicitly requested by user

## Persistent Monitoring and Automation

### Automated Verification (When Persistent Mode Enabled)

When the level-set-agent is invoked with persistent monitoring enabled, it will:

1. **Automated Tool Count Verification:**
   - Scan `Cyrano/src/tools/` directory and count actual tool files
   - Count tool definitions in `Cyrano/src/mcp-server.ts`
   - Compare with documented tool counts in README.md and other docs
   - Flag discrepancies automatically
   - Update documentation if count differs by more than 5%

2. **Documentation Cross-Referencing:**
   - Verify all cross-references in documentation are valid
   - Check that referenced files exist
   - Validate that section references are accurate
   - Flag broken links or outdated references
   - Update cross-references when files are moved or renamed

3. **Automatic Tracking:**
   - Track documentation update dates vs. code modification dates
   - Identify documents that haven't been updated after related code changes
   - Monitor version numbers for consistency
   - Track project status across all tracking documents
   - Generate discrepancy reports automatically

4. **Continuous Monitoring:**
   - Run lightweight checks on each documentation update
   - Verify tool counts after new tools are added
   - Check cross-references when documents are modified
   - Validate status consistency across tracking documents
   - Alert on significant discrepancies

5. **File Existence Validation:**
   - Verify all referenced file paths in documentation actually exist
   - Check that tool names listed in documentation match actual tool registrations in `mcp-server.ts`
   - Validate that tool file paths (e.g., "In tool-enhancer.ts") correspond to existing files
   - Flag non-existent tools or files as critical errors
   - Cross-reference tool definitions between documentation and code

6. **Definition Cross-Checking:**
   - Verify engine names and descriptions match between documentation and code (e.g., MAE = Multi-Agent Engine, not Mutual Assent Engine)
   - Check that acronym definitions are consistent across all documents
   - Validate tool descriptions match actual implementations
   - Flag definition mismatches as critical errors
   - Ensure terminology consistency across codebase and documentation

7. **Tool Registry Validation:**
   - Compare tool names in `TOOL_REGISTRY_CHECKLIST.md` with actual tool registrations in `mcp-server.ts`
   - Verify all tools listed as "Implementation complete" actually exist
   - Check that tool status matches actual implementation state
   - Flag tools listed but not registered, or registered but not listed
   - Validate tool grouping and categorization

### Persistent Mode Configuration

To enable persistent monitoring, the agent should:
- Run automated checks after each major code change
- Perform weekly documentation consistency scans
- Generate monthly discrepancy reports
- Maintain a discrepancy tracking log
- Auto-update minor discrepancies (with user notification)
