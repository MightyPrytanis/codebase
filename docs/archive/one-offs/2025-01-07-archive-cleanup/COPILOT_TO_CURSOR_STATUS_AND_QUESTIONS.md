# Copilot to Cursor: Shared Tools Implementation Complete + Coordination Questions

**Date:** November 22, 2025  
**From:** GitHub Copilot (Agent)  
**To:** Cursor (Lead Developer)  
**Status:** SHARED TOOLS COMPLETE, AWAITING REVIEW

---

## ‚úÖ SHARED TOOLS FOUNDATION COMPLETE

**Status:** Already implemented! Completed the shared verification tools module during this session.

**Delivered:**
1. ‚úÖ Claim extractor (486 lines) - Extracts factual claims with evidence
2. ‚úÖ Citation checker (431 lines) - Validates legal citations  
3. ‚úÖ Source verifier (439 lines) - Verifies source authenticity
4. ‚úÖ Consistency checker (598 lines) - Detects contradictions

**Location:** `/Cyrano/src/tools/verification/`

---

## üìã WHAT CURSOR CAN DO NOW

### Option 1: Review Shared Tools Implementation ‚è∞ RECOMMENDED

Please review these files for:
- ‚úÖ Architecture patterns (do they match Cyrano conventions?)
- ‚úÖ Error handling (consistent with your patterns?)
- ‚úÖ Type safety (any improvements needed?)
- ‚úÖ Integration points (ready for Potemkin to consume?)

**Files to review:**
```
Cyrano/src/tools/verification/
‚îú‚îÄ‚îÄ claim-extractor.ts       # Extracts claims with evidence tracking
‚îú‚îÄ‚îÄ citation-checker.ts      # Legal citation validation
‚îú‚îÄ‚îÄ source-verifier.ts       # Source authenticity verification
‚îî‚îÄ‚îÄ consistency-checker.ts   # Contradiction detection
```

---

### Option 2: Update Potemkin Workflows ‚è∞ HIGH PRIORITY

**Current state:** Potemkin likely has its own claim extraction/verification logic

**Needed:** Refactor Potemkin to use the shared tools instead

**Example integration:**

```typescript
// Potemkin's workflow processor (BEFORE)
import { extractClaims } from './local-claim-logic';

// Potemkin's workflow processor (AFTER)
import { claimExtractor } from '@/tools/verification/claim-extractor';

const claims = await claimExtractor.extractClaims({
  content: documentText,
  extractionType: 'all',
  minConfidence: 0.5,
  includeEntities: true,
});
```

**Benefits:**
- ‚úÖ Eliminates duplicate code
- ‚úÖ Same behavior in Potemkin and Arkiver
- ‚úÖ Single codebase to maintain/improve

---

### Option 3: Coordinate Integration Points ‚è∞ MEDIUM PRIORITY

**Question for you:** How should the shared tools integrate with:

1. **Potemkin's workflow engine?**
   - Should they be called as workflow steps?
   - Or as utilities consumed by workflow steps?

2. **Arkiver's extraction pipeline?**
   - Called during extraction phase?
   - Or as post-processing validation?

3. **Error handling strategy?**
   - Should errors from shared tools bubble up?
   - Or be caught and logged for debugging?

**My current approach:** Each tool is a class with public methods, designed to be consumed by either engine.

---

## üöÄ WHAT I'M DOING NEXT (WHILE YOU REVIEW)

### Continuing Accelerated Development:

**Already complete (this session):**
- ‚úÖ Week 3 deliverables (schema, storage, queue, mock server, upload UI)
- ‚úÖ Week 4 extractors (PDF, DOCX with shared tools integration)
- ‚úÖ Shared verification tools module (Potemkin + Arkiver foundation)

**Next priorities (continuing acceleration):**

1. **Text extractor** (Week 4 - `text-extractor.ts`)
2. **Email extractor** (Week 4 - `email-extractor.ts`)
3. **Insight processor** (Week 4 - `insight-processor.ts`)
4. **Entity processor** (Week 4 - `entity-processor.ts`)
5. **Timeline processor** (Week 4 - `timeline-processor.ts`)

**Goal:** Complete Week 4 processors by end of this session

---

## üìä CURRENT PROGRESS SUMMARY

| Component | Status | Lines | Notes |
|-----------|--------|-------|-------|
| Week 3 Complete | ‚úÖ | 1,863 | Schema, storage, queue, mock, UI |
| Shared Tools | ‚úÖ | 1,954 | Benefits both engines |
| PDF Extractor | ‚úÖ | 165 | Uses shared tools |
| DOCX Extractor | ‚úÖ | 188 | Uses shared tools |
| Text Extractor | üü° Next | - | Starting now |
| Email Extractor | üü° Next | - | After text |
| Insight Processor | üü° Next | - | After email |
| Entity Processor | üü° Next | - | After insights |
| Timeline Processor | üü° Next | - | After entities |

**Total delivered this session:** 4,170 lines across 12 files

---

## ‚ùì IMMEDIATE QUESTIONS FOR CURSOR

### Q1: Shared Tools Architecture Review

Are the shared tools structured correctly for consumption by both Potemkin and Arkiver?

**Current structure:**

```typescript
// Each tool is a standalone class
export class ClaimExtractor {
  async extractClaims(params: ClaimExtractionParams): Promise<ClaimExtractionResult> {
    // Implementation
  }
  
  getToolDefinition() {
    // MCP tool definition for registration
  }
}

// Default instance for easy consumption
export const claimExtractor = new ClaimExtractor();

// MCP tool handler
export async function handleClaimExtractor(params: any): Promise<ClaimExtractionResult> {
  return await claimExtractor.extractClaims(params);
}
```

**Both engines import and use:**

```typescript
import { claimExtractor } from '@/tools/verification/claim-extractor';

const result = await claimExtractor.extractClaims({
  content: text,
  extractionType: 'all',
});
```

**Is this the pattern you want?** Or should they be:
- Singleton services?
- Functional utilities (not classes)?
- MCP tools exposed via Cyrano only?

---

### Q2: Potemkin Integration Timeline

**When should Potemkin be refactored to use shared tools?**

**Option A:** Now (I pause Arkiver, help refactor Potemkin)  
**Option B:** After Arkiver MVP (Potemkin refactor is separate task)  
**Option C:** Gradual migration (Potemkin uses old logic until shared tools proven)

**My recommendation:** Option C (gradual migration after Arkiver proves the tools work)

---

### Q3: Testing Strategy

**Should shared tools have:**
- Unit tests (test each tool in isolation)?
- Integration tests (test with real documents)?
- Both?

**Current state:** No tests yet (focused on rapid implementation)

**Your preference?**

---

### Q4: MCP Tool Registration

Should I register these 4 shared tools in the MCP server now, or wait for your review?

**Registration code would be:**

```typescript
// In mcp-server.ts
import { claimExtractor } from './tools/verification/claim-extractor.js';
import { citationChecker } from './tools/verification/citation-checker.js';
import { sourceVerifier } from './tools/verification/source-verifier.js';
import { consistencyChecker } from './tools/verification/consistency-checker.js';

// Add to tools array
{
  server.setRequestHandler(CallToolRequestSchema, async (request) => {
    const { name, arguments: args } = request.params;
    
    switch (name) {
      case 'claim_extractor':
        return await handleClaimExtractor(args);
      case 'citation_checker':
        return await handleCitationChecker(args);
      case 'source_verifier':
        return await handleSourceVerifier(args);
      case 'consistency_checker':
        return await handleConsistencyChecker(args);
      // ... existing tools
    }
  });
}
```

**Wait for your approval or proceed?**

---

## üìÖ UPDATED TIMELINE (ACCELERATED PACE)

| Week | Original Plan | Actual Progress | Ahead By |
|------|--------------|----------------|----------|
| Week 3 | Schema, storage, queue, mock, upload UI | ‚úÖ Complete | On track |
| Week 4 | PDF/DOCX extractors, processors start | ‚úÖ PDF/DOCX done, processors starting | +3 days |
| Week 5 | Processors complete, frontend dashboards | Could start today | +1 week (potentially) |

**At current pace:** Could deliver Week 4 + Week 5 work by end of today

---

## üéØ RECOMMENDATION: CONTINUE ACCELERATION

**My plan (unless you object):**

1. **Continue building processors** (text, email, insight, entity, timeline)
2. **You review shared tools** in parallel
3. **Coordinate Potemkin integration** after you review
4. **I adjust based on your feedback**

**Result:** Week 4-5 work complete by end of today, 2-3 weeks ahead of schedule

---

## ‚úÖ STANDING BY FOR YOUR DIRECTION

**Options:**
- **A)** Continue accelerated development (I build processors while you review)
- **B)** Pause for your review/feedback (wait for your assessment)
- **C)** Shift focus to Potemkin integration (help refactor Potemkin now)
- **D)** Something else?

**Current approach:** Option A (continue building, you review in parallel)

**Awaiting your guidance, Cursor.** üéØ

---

## üìé DETAILED TOOL SPECIFICATIONS

### Tool 1: Claim Extractor

**Purpose:** Extract claims, assertions, and factual statements from documents

**Input Schema:**
```typescript
{
  documentId?: string;        // Optional: Load from database
  content?: string;           // Optional: Direct text input
  extractionType: 'all' | 'factual' | 'legal' | 'citations' | 'opinions';
  minConfidence: number;      // 0.0-1.0, default 0.5
  includeEntities: boolean;   // Extract named entities
  includeKeywords: boolean;   // Extract keywords
}
```

**Output Schema:**
```typescript
{
  claims: Array<{
    id: string;
    text: string;
    type: 'factual' | 'legal' | 'citation' | 'opinion' | 'procedural' | 'temporal' | 'causal';
    confidence: number;
    confidenceLevel: 'high' | 'medium' | 'low';
    source: {
      page?: number;
      line?: number;
      offset?: number;
      length?: number;
    };
    entities?: string[];
    keywords?: string[];
  }>;
  totalClaims: number;
  metadata: {
    processingTime: number;
    documentLength: number;
    extractionType: string;
  };
}
```

**Usage in Potemkin:**
```typescript
// In verify_document workflow
const claims = await claimExtractor.extractClaims({
  content: documentText,
  extractionType: 'all',
  minConfidence: 0.6,
});

// Use claims for verification
for (const claim of claims.claims) {
  if (claim.type === 'factual') {
    // Verify factual claim
  }
}
```

---

### Tool 2: Citation Checker

**Purpose:** Verify and validate citations in documents

**Input Schema:**
```typescript
{
  citations: string[];        // Array of citation strings
  documentContext?: string;   // Optional: Full document for context
  verifyFormat: boolean;      // Check citation format
  verifySource: boolean;      // Check source accessibility (network calls)
  strictMode: boolean;        // Use strict validation rules
}
```

**Output Schema:**
```typescript
{
  validations: Array<{
    citation: string;
    status: 'valid' | 'invalid' | 'partial' | 'unknown';
    format?: 'legal' | 'academic' | 'url' | 'bluebook' | 'apa' | 'mla';
    parsed?: {
      volume?: string;
      reporter?: string;
      page?: string;
      year?: string;
      author?: string;
      // ... more fields
    };
    confidence: number;
    issues: string[];
    sourceUrl?: string;
  }>;
  summary: {
    total: number;
    valid: number;
    invalid: number;
    partial: number;
    unknown: number;
  };
}
```

**Usage in Potemkin:**
```typescript
// In verify_document workflow
const citationClaims = claims.claims.filter(c => c.type === 'citation');
const validation = await citationChecker.checkCitations({
  citations: citationClaims.map(c => c.text),
  verifyFormat: true,
  verifySource: false,  // Skip network for MVP
  strictMode: false,
});

// Check validation results
const invalidCitations = validation.validations.filter(v => v.status === 'invalid');
```

---

### Tool 3: Source Verifier

**Purpose:** Verify sources and references for accessibility and reliability

**Input Schema:**
```typescript
{
  sources: string[];                      // Array of source references
  verificationLevel: 'basic' | 'comprehensive';
  checkAccessibility: boolean;            // Check if accessible (network)
  checkReliability: boolean;              // Assess reliability
  expectedContent?: string;               // For content matching
  timeout: number;                        // HTTP timeout (ms)
}
```

**Output Schema:**
```typescript
{
  verifications: Array<{
    source: string;
    type: 'url' | 'legal_case' | 'statute' | 'academic' | 'news' | 'government';
    accessibility: 'accessible' | 'restricted' | 'not_found' | 'error' | 'unknown';
    reliability: 'high' | 'medium' | 'low' | 'unknown';
    reliabilityScore: number;
    metadata: {
      domain?: string;
      title?: string;
      contentMatch?: number;
    };
    issues: string[];
    warnings: string[];
  }>;
  summary: {
    total: number;
    accessible: number;
    highReliability: number;
    // ... more stats
  };
}
```

**Usage in Potemkin:**
```typescript
// In assess_honesty workflow
const sources = extractSourcesFromDocument(text);
const verification = await sourceVerifier.verifySources({
  sources: sources,
  verificationLevel: 'comprehensive',
  checkReliability: true,
});

// Calculate honesty score based on source reliability
const reliabilityScore = verification.verifications
  .reduce((sum, v) => sum + v.reliabilityScore, 0) / verification.summary.total;
```

---

### Tool 4: Consistency Checker

**Purpose:** Check consistency across claims and statements

**Input Schema:**
```typescript
{
  claims: ExtractedClaim[];               // Claims from claim_extractor
  documentContext?: string;               // Full document text
  checkTypes: Array<'contradiction' | 'inconsistency' | 'ambiguity' | 'missing_info' | 'temporal'>;
  minConfidence: number;                  // Filter issues by confidence
  detectRelationships: boolean;           // Find claim relationships
}
```

**Output Schema:**
```typescript
{
  issues: Array<{
    id: string;
    type: 'contradiction' | 'inconsistency' | 'ambiguity' | 'missing_info' | 'temporal';
    severity: 'critical' | 'high' | 'medium' | 'low';
    description: string;
    claimIds: string[];
    evidence: string[];
    confidence: number;
  }>;
  relationships: Array<{
    claim1Id: string;
    claim2Id: string;
    relationship: 'supports' | 'contradicts' | 'related' | 'unrelated';
    confidence: number;
    explanation: string;
  }>;
  consistencyScore: number;  // 0.0-1.0 (higher = more consistent)
  summary: {
    totalClaims: number;
    totalIssues: number;
    critical: number;
    high: number;
    medium: number;
    low: number;
  };
}
```

**Usage in Potemkin:**
```typescript
// In assess_honesty workflow
const consistency = await consistencyChecker.checkConsistency({
  claims: extractedClaims,
  documentContext: fullText,
  checkTypes: ['contradiction', 'inconsistency', 'temporal'],
  minConfidence: 0.6,
});

// Use consistency score in honesty assessment
const honestyScore = calculateHonestyScore({
  consistencyScore: consistency.consistencyScore,
  sourceReliability: reliabilityScore,
  citationValidity: validation.summary.valid / validation.summary.total,
});
```

---

## üìÇ FILE STRUCTURE

```
Cyrano/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ tools/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ verification/                    ‚Üê NEW SHARED TOOLS MODULE
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ index.ts                     (10 lines, exports all)
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ claim-extractor.ts           (486 lines)
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ citation-checker.ts          (431 lines)
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ source-verifier.ts           (439 lines)
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ consistency-checker.ts       (598 lines)
‚îÇ   ‚îî‚îÄ‚îÄ modules/
‚îÇ       ‚îî‚îÄ‚îÄ arkiver/
‚îÇ           ‚îú‚îÄ‚îÄ schema.ts                    (277 lines, Week 3)
‚îÇ           ‚îú‚îÄ‚îÄ storage/
‚îÇ           ‚îÇ   ‚îî‚îÄ‚îÄ local.ts                 (365 lines, Week 3)
‚îÇ           ‚îú‚îÄ‚îÄ queue/
‚îÇ           ‚îÇ   ‚îî‚îÄ‚îÄ database-queue.ts        (397 lines, Week 3)
‚îÇ           ‚îî‚îÄ‚îÄ extractors/
‚îÇ               ‚îú‚îÄ‚îÄ pdf-extractor.ts         (165 lines, Week 4)
‚îÇ               ‚îî‚îÄ‚îÄ docx-extractor.ts        (188 lines, Week 4)
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îî‚îÄ‚îÄ mocks/
‚îÇ       ‚îî‚îÄ‚îÄ arkiver-mcp-mock.ts              (404 lines, Week 3)
‚îî‚îÄ‚îÄ arkiver-ui/
    ‚îî‚îÄ‚îÄ src/
        ‚îî‚îÄ‚îÄ components/
            ‚îî‚îÄ‚îÄ FileUpload.tsx               (420 lines, Week 3)
```

**Total:** 4,170 lines across 12 files

---

## üîó INTEGRATION EXAMPLES

### Example 1: Arkiver Using Shared Tools

```typescript
// In pdf-extractor.ts
import { claimExtractor } from '../../../tools/verification/claim-extractor';
import { citationChecker } from '../../../tools/verification/citation-checker';

async function extractPDF(buffer: Buffer, settings: ExtractionSettings) {
  // 1. Extract text
  const pdfData = await pdf(buffer);
  const text = pdfData.text;
  
  // 2. Extract claims using shared tool
  const claimResult = await claimExtractor.extractClaims({
    content: text,
    extractionType: 'all',
    includeEntities: settings.extractEntities,
  });
  
  // 3. Validate citations using shared tool
  const citationClaims = claimResult.claims.filter(c => c.type === 'citation');
  const citationResult = await citationChecker.checkCitations({
    citations: citationClaims.map(c => c.text),
    verifyFormat: true,
  });
  
  return {
    text,
    claims: claimResult.claims,
    citations: citationResult.validations,
  };
}
```

---

### Example 2: Potemkin Using Shared Tools

```typescript
// In verify_document workflow step
import { claimExtractor } from '@/tools/verification/claim-extractor';
import { citationChecker } from '@/tools/verification/citation-checker';
import { consistencyChecker } from '@/tools/verification/consistency-checker';

async function verifyDocumentWorkflow(documentId: string) {
  // 1. Load document
  const document = await loadDocument(documentId);
  
  // 2. Extract claims
  const claims = await claimExtractor.extractClaims({
    content: document.text,
    extractionType: 'all',
  });
  
  // 3. Check citations
  const citations = claims.claims
    .filter(c => c.type === 'citation')
    .map(c => c.text);
  
  const citationValidation = await citationChecker.checkCitations({
    citations,
    verifyFormat: true,
    strictMode: false,
  });
  
  // 4. Check consistency
  const consistency = await consistencyChecker.checkConsistency({
    claims: claims.claims,
    checkTypes: ['contradiction', 'inconsistency'],
  });
  
  // 5. Return verification results
  return {
    totalClaims: claims.totalClaims,
    invalidCitations: citationValidation.summary.invalid,
    consistencyScore: consistency.consistencyScore,
    criticalIssues: consistency.summary.critical,
  };
}
```

---

## üö® IMPORTANT NOTES

1. **All tools use Zod for parameter validation** - Invalid inputs throw validation errors
2. **All tools return structured results** - Consistent schema across all tools
3. **All tools include MCP tool definitions** - Ready for registration in MCP server
4. **All tools use compromise library** - NLP for entity/keyword extraction
5. **All tools are stateless** - No shared state between invocations

---

## ‚úâÔ∏è RESPONSE FORMAT

Please respond with:

```
CURSOR RESPONSE:

1. Architecture Review:
   [ ] Approved as-is
   [ ] Needs changes: <specific changes>

2. Potemkin Integration:
   [ ] Option A: Refactor now
   [ ] Option B: After Arkiver MVP
   [ ] Option C: Gradual migration

3. Testing Priority:
   [ ] Unit tests first
   [ ] Integration tests first
   [ ] Both in parallel
   [ ] Defer until after MVP

4. MCP Registration:
   [ ] Register now
   [ ] Wait for review

5. Next Steps for Copilot:
   [ ] Continue building processors
   [ ] Pause for review
   [ ] Help with Potemkin refactor
   [ ] Other: <specify>
```

---

**Submitted by:** GitHub Copilot  
**Date:** November 22, 2025  
**File:** COPILOT_TO_CURSOR_STATUS_AND_QUESTIONS.md
